{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis - CNN vs LSTM\n","metadata":{"_uuid":"06b2f92a18e4dffdec2c8bf2eb11da5fc7749039"}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom nltk import ngrams\nimport string\n \nstop_words=['da','ng','noi','sidi','the','bony','kaiku','tantha','cd','of','and','it','ngna','akhoi','eikhoi','eid','cgi','manipuri','cbu','nupase','nupise','hero','mi','ei','eidi','na','album','bala','c','se','esei','gi','su',]\n#stop_words=[] \n# clean words, i.e. remove stopwords and punctuation\ndef clean_words(words, stop_words):\n    words_clean = ''\n    for word in words.split():\n        word = word.lower()\n        if word not in stop_words and word not in string.punctuation:\n            words_clean=words_clean+' '+word   \n    return words_clean \n \n\n\nshort_pos = open(\"pos.txt\",\"r\").read()\nshort_neg = open(\"neg.txt\",\"r\").read()\n\npos_reviews=[]\nneg_reviews=[]\nfor r in short_pos.split('\\n'):\n    pos_reviews.append(clean_words(r, stop_words))\n\nfor r in short_neg.split('\\n'):\n    neg_reviews.append(clean_words(r, stop_words))\n\n    \nfrom random import shuffle \nshuffle(pos_reviews)\nshuffle(neg_reviews)\ntrain_docs=pos_reviews[:1500]+neg_reviews[:1500]\n","metadata":{"_uuid":"7ae25bd115e5bb42c4ec5ae0592eabdb2561f63d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom numpy import array\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_docs)\nencoded_docs = tokenizer.texts_to_sequences(train_docs)\n\nmax_length = max([len(s.split()) for s in train_docs])\nXtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n\nytrain = array([0 for _ in range(1500)] + [1 for _ in range(1500)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_docs = pos_reviews[1500:2000]+neg_reviews[1500:2000]\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(test_docs)\n# pad sequences\nXtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n# define test labels\nytest = array([0 for _ in range(500)] + [1 for _ in range(500)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Embedding\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 100, input_length=max_length))\nmodel.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile network\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit network\nmodel.fit(Xtrain, ytrain, epochs=10, verbose=2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\nimport numpy as np\n\ny_pred_labels = model.predict_classes(Xtest, verbose=0)\nconfusion_matrix = metrics.confusion_matrix(y_true=ytest, y_pred=y_pred_labels)  # shape=(12, 12)\nprint(confusion_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = model.evaluate(Xtest, ytest, verbose=0)\nprint('Test Accuracy: %f' % (acc*100))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nfrom keras.layers import Dense, Embedding,LSTM\nfrom keras.models import Sequential\n\n# Input / Embdedding\nmodel.add(Embedding(vocab_size,100,input_length=max_length,mask_zero=True))\nmodel.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\nmodel.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n\n# Output layer\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 5\nbatch_size = 32\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(Xtrain, ytrain, validation_data=(Xtest, ytest), epochs=epochs, batch_size=batch_size, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import LSTM\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 100, input_length=max_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())\nmodel.fit(Xtrain, ytrain, validation_data=(Xtest, ytest), epochs=3, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(Xtest, ytest, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\nimport numpy as np\n\ny_pred_labels = model.predict_classes(Xtest, verbose=0)\nconfusion_matrix = metrics.confusion_matrix(y_true=ytest, y_pred=y_pred_labels)  # shape=(12, 12)\nprint(confusion_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab_size, 100, input_length=max_length))\nmodel.add(Flatten())\nmodel.add(Dense(250, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nmodel.fit(Xtrain, ytrain, epochs=10, batch_size=128, verbose=2)\n# Final evaluation of the model\nscores = model.evaluate(Xtest, ytest, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\nimport numpy as np\n\ny_pred_labels = model.predict_classes(Xtest, verbose=0)\nconfusion_matrix = metrics.confusion_matrix(y_true=ytest, y_pred=y_pred_labels)  # shape=(12, 12)\nprint(confusion_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}